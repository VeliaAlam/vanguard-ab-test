{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5257e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba71b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_2 = pd.read_csv(\"df_pivot_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bbecd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>Variation</th>\n",
       "      <th>clnt_tenure_yr</th>\n",
       "      <th>age_group</th>\n",
       "      <th>confirm</th>\n",
       "      <th>start</th>\n",
       "      <th>step_1</th>\n",
       "      <th>step_2</th>\n",
       "      <th>step_3</th>\n",
       "      <th>drop_start_step_1</th>\n",
       "      <th>...</th>\n",
       "      <th>confirm_filled</th>\n",
       "      <th>time_confirm</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_step_1</th>\n",
       "      <th>time_step_2</th>\n",
       "      <th>time_step_3</th>\n",
       "      <th>error_start_step_1</th>\n",
       "      <th>error_step_1_step_2</th>\n",
       "      <th>error_step_2_step_3</th>\n",
       "      <th>error_step_3_confirm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>647</td>\n",
       "      <td>Test</td>\n",
       "      <td>12.0</td>\n",
       "      <td>55-64</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>934</td>\n",
       "      <td>Test</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1028</td>\n",
       "      <td>Control</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538.0</td>\n",
       "      <td>2690.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>Control</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50482</th>\n",
       "      <td>9999150</td>\n",
       "      <td>Test</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50483</th>\n",
       "      <td>9999400</td>\n",
       "      <td>Test</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50484</th>\n",
       "      <td>9999626</td>\n",
       "      <td>Test</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50485</th>\n",
       "      <td>9999729</td>\n",
       "      <td>Test</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50486</th>\n",
       "      <td>9999832</td>\n",
       "      <td>Test</td>\n",
       "      <td>23.0</td>\n",
       "      <td>45-54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50487 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_id Variation  clnt_tenure_yr age_group  confirm  start  step_1  \\\n",
       "0            555      Test             3.0     25-34      5.0    5.0     5.0   \n",
       "1            647      Test            12.0     55-64      5.0    5.0     5.0   \n",
       "2            934      Test             9.0     45-54      NaN    4.0     NaN   \n",
       "3           1028   Control            12.0     35-44      NaN    9.0     9.0   \n",
       "4           1104   Control             5.0     45-54      NaN    1.0     NaN   \n",
       "...          ...       ...             ...       ...      ...    ...     ...   \n",
       "50482    9999150      Test             5.0     25-34      NaN    3.0     3.0   \n",
       "50483    9999400      Test             7.0     25-34      5.0    5.0     5.0   \n",
       "50484    9999626      Test             9.0     25-34      NaN    2.0     2.0   \n",
       "50485    9999729      Test            10.0     25-34      5.0    2.0     2.0   \n",
       "50486    9999832      Test            23.0     45-54      NaN    2.0     2.0   \n",
       "\n",
       "       step_2  step_3  drop_start_step_1  ...  confirm_filled  time_confirm  \\\n",
       "0         5.0     5.0                0.0  ...             5.0         158.0   \n",
       "1         5.0     5.0                0.0  ...             5.0         377.0   \n",
       "2         NaN     NaN                NaN  ...             0.0           NaN   \n",
       "3         9.0     9.0                0.0  ...             0.0           NaN   \n",
       "4         NaN     NaN                NaN  ...             0.0           NaN   \n",
       "...       ...     ...                ...  ...             ...           ...   \n",
       "50482     NaN     NaN                0.0  ...             0.0           NaN   \n",
       "50483     5.0     5.0                0.0  ...             5.0         119.0   \n",
       "50484     NaN     NaN                0.0  ...             0.0           NaN   \n",
       "50485     5.0     5.0                0.0  ...             5.0          75.0   \n",
       "50486     NaN     NaN                0.0  ...             0.0           NaN   \n",
       "\n",
       "       time_start time_step_1  time_step_2  time_step_3  error_start_step_1  \\\n",
       "0           158.0       158.0        158.0        158.0                   0   \n",
       "1           377.0       377.0        377.0        377.0                   0   \n",
       "2           568.0         NaN          NaN          NaN                   0   \n",
       "3           538.0      2690.0       1076.0        538.0                   0   \n",
       "4             0.0         NaN          NaN          NaN                   0   \n",
       "...           ...         ...          ...          ...                 ...   \n",
       "50482        36.0        18.0          NaN          NaN                   0   \n",
       "50483       119.0       119.0        119.0        119.0                   0   \n",
       "50484         8.0         8.0          NaN          NaN                   0   \n",
       "50485       990.0       540.0        525.0         75.0                   0   \n",
       "50486         8.0         8.0          NaN          NaN                   0   \n",
       "\n",
       "       error_step_1_step_2  error_step_2_step_3  error_step_3_confirm  \n",
       "0                        0                    0                     0  \n",
       "1                        0                    0                     0  \n",
       "2                        0                    0                     0  \n",
       "3                        0                    0                     0  \n",
       "4                        0                    0                     0  \n",
       "...                    ...                  ...                   ...  \n",
       "50482                    0                    0                     0  \n",
       "50483                    0                    0                     0  \n",
       "50484                    0                    0                     0  \n",
       "50485                    0                    0                     0  \n",
       "50486                    0                    0                     0  \n",
       "\n",
       "[50487 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3c309",
   "metadata": {},
   "source": [
    "**1.- Completion Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc4d38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-test statistic: -8.8927, p-value: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Completion Rate Hypothesis Test\n",
    "###Objective: Test whether the new design (Test) has a significantly higher completion rate than the old design (Control).\n",
    "\n",
    "# H0 : p-test = p-control --> There is no difference in completion rates between Test and Control.\n",
    "# H1 : p-test > p-control --> Test has a higher completion rate than Control.\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Count of completions\n",
    "successes = df_pivot_2.groupby('Variation')['confirm_filled'].apply(lambda x: (x>0).sum())\n",
    "# Total users\n",
    "nobs = df_pivot_2.groupby('Variation')['confirm_filled'].count()\n",
    "\n",
    "z_stat, p_value = proportions_ztest(count=successes, nobs=nobs, alternative='larger')\n",
    "print(f\"Z-test statistic: {z_stat:.4f}, p-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7216b882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We fail to reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "##Desicion making\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis, Test completion rate is significantly higher\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e130175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion Rate Increase: 3.71%\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Completion Rate Cost-Effectiveness Threshold\n",
    "###Objective: Check whether the increase in completion rate exceeds 5%, which is required to justify the redesign costs.\n",
    "\n",
    "completion_rate = df_pivot_2.groupby('Variation')['confirm_filled'].apply(lambda x: (x>0).mean())\n",
    "increase = completion_rate['Test'] - completion_rate['Control']\n",
    "print(f\"Completion Rate Increase: {increase*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2315f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eeddb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ The redesign does NOT justify the costs, as the increase is below 5%.\n"
     ]
    }
   ],
   "source": [
    "if increase >= 5:\n",
    "    print(\"✅ The redesign meets the 5% cost-effectiveness threshold.\")\n",
    "else:\n",
    "    print(\"⚠️ The redesign does NOT justify the costs, as the increase is below 5%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b0cbc",
   "metadata": {},
   "source": [
    "- **Hypothesis Test (Step 1)**:\n",
    "    \n",
    "    - **H0**: No difference between Test and Control.\n",
    "    - **H1**: Test has a higher completion rate than Control.\n",
    "    - **Result**: Z = -8.8927, p = 1.000 → **Fail to reject H0.**\n",
    "    - **Conclusion**: The observed higher completion rate in Test is **not statistically significant**.\n",
    "\n",
    "- **Cost-Effectiveness Threshold (Step 2)**:\n",
    "    - **Increase**: 3.71%\n",
    "    - **Threshold**: 5%\n",
    "    - **Conclusion: ⚠️ Redesign does NOT justify the costs**, as the increase is below 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f57dcef",
   "metadata": {},
   "source": [
    "**2.- Average Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3efed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Average Age Hypothesis Test ===\n",
      "T-statistic: -2.5909, p-value: 0.0096\n",
      "✅ Significant difference in average age between Control and Test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/q0jpdzq126j54kx_lzjc4dcm0000gn/T/ipykernel_44422/2647169424.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_pivot_2['age_num'] = df_pivot_2['age_group'].replace({'<25':22, '25-34':30, '35-44':40, '45-54':50, '55-64':60, '65+':70})\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "#Step 3: Hypothesis Testing for Average Age\n",
    "# H0: mean age is the same for Control and Test\n",
    "# H1: mean age is different\n",
    "df_pivot_2['age_num'] = df_pivot_2['age_group'].replace({'<25':22, '25-34':30, '35-44':40, '45-54':50, '55-64':60, '65+':70})\n",
    "control_age = df_pivot_2[df_pivot_2['Variation']=='Control']['age_num'].dropna()\n",
    "test_age = df_pivot_2[df_pivot_2['Variation']=='Test']['age_num'].dropna()\n",
    "t_stat_age, p_value_age = ttest_ind(test_age, control_age, equal_var=False)\n",
    "\n",
    "print(\"\\n=== Average Age Hypothesis Test ===\")\n",
    "print(f\"T-statistic: {t_stat_age:.4f}, p-value: {p_value_age:.4f}\")\n",
    "if p_value_age < 0.05:\n",
    "    print(\"✅ Significant difference in average age between Control and Test.\")\n",
    "else:\n",
    "    print(\"⚠️ No significant difference in average age.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f4c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Age Distribution Table ===\n",
      "age_group  25-34  35-44  45-54  55-64   65+   <25\n",
      "Variation                                        \n",
      "Control     4817   3966   4607   5069  3313  1754\n",
      "Test        5712   4560   5353   5621  3670  2045\n",
      "\n",
      "=== Age Group Chi-Square Test ===\n",
      "Chi2 statistic: 8.7141, p-value: 0.1210, dof: 5\n",
      "⚠️ No significant difference in age distribution between Control and Test.\n",
      "\n",
      "=== Expected Frequencies ===\n",
      "age_group        25-34       35-44        45-54        55-64          65+  \\\n",
      "Variation                                                                   \n",
      "Control    4906.317547  3972.95692  4641.174164  4981.340543  3253.947709   \n",
      "Test       5622.682453  4553.04308  5318.825836  5708.659457  3729.052291   \n",
      "\n",
      "age_group          <25  \n",
      "Variation               \n",
      "Control    1770.263117  \n",
      "Test       2028.736883  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Contingency table Between Variation and Age group\n",
    "age_table = pd.crosstab(df_pivot_2['Variation'], df_pivot_2['age_group'])\n",
    "\n",
    "print(\"=== Age Distribution Table ===\")\n",
    "print(age_table)\n",
    "\n",
    "# Test chi-square\n",
    "chi2, p_val, dof, expected = chi2_contingency(age_table)\n",
    "\n",
    "print(\"\\n=== Age Group Chi-Square Test ===\")\n",
    "print(f\"Chi2 statistic: {chi2:.4f}, p-value: {p_val:.4f}, dof: {dof}\")\n",
    "if p_val < 0.05:\n",
    "    print(\"✅ Significant difference in age distribution between Control and Test.\")\n",
    "else:\n",
    "    print(\"⚠️ No significant difference in age distribution between Control and Test.\")\n",
    "\n",
    "print(\"\\n=== Expected Frequencies ===\")\n",
    "print(pd.DataFrame(expected, index=age_table.index, columns=age_table.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a37f9",
   "metadata": {},
   "source": [
    "- **T-Test:** t = -2.5909, p = 0.0096 → ✅ Significant difference in average age between Test and Control.\n",
    "\n",
    "- **Chi-Square Test on Age Distribution**: Chi2 = 8.7141, p = 0.121 → ⚠️ No significant difference in age distribution between groups.\n",
    "\n",
    "- **Conclusion**: Although the mean age differs slightly, the overall age distribution is similar between Test and Control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565c94f",
   "metadata": {},
   "source": [
    "**3.- Tenure Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7341ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tenure Distribution Chi-Square Test ===\n",
      "tenure_group  less-tenured  more-tenured\n",
      "Variation                               \n",
      "Control              11813         11713\n",
      "Test                 13349         13612\n",
      "Chi2: 2.4364, p-value: 0.1185\n",
      "⚠️ Not significant\n"
     ]
    }
   ],
   "source": [
    "### 2. Distribution for tenure (Chi-square)\n",
    "tenure_table = pd.crosstab(df_pivot_2['Variation'], df_pivot_2['tenure_group'])\n",
    "chi2, p_val, dof, expected = chi2_contingency(tenure_table)\n",
    "\n",
    "print(\"\\n=== Tenure Distribution Chi-Square Test ===\")\n",
    "print(tenure_table)\n",
    "print(f\"Chi2: {chi2:.4f}, p-value: {p_val:.4f}\")\n",
    "print(\"✅ Significant\" if p_val < 0.05 else \"⚠️ Not significant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aebdea",
   "metadata": {},
   "source": [
    "- **Chi-Square Test**: Chi2 = 2.4364, p = 0.1185 → ⚠️ Not significant.\n",
    "- **Conclusion**: The split between less-tenured and more-tenured users is similar across Test and Control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83030379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abtest = pd.read_csv(\"df_abtest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb2519bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['client_id', 'Variation', 'clnt_tenure_yr', 'clnt_tenure_mnth',\n",
       "       'clnt_age', 'gendr', 'num_accts_x', 'bal_x', 'calls_6_mnth_x',\n",
       "       'logons_6_mnth_x', 'visitor_id', 'visit_id', 'process_step',\n",
       "       'date_time', 'source', 'num_steps', 'session_duration_sec',\n",
       "       'num_accts_y', 'bal_y', 'calls_6_mnth_y', 'logons_6_mnth_y',\n",
       "       'num_sessions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6efd128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['client_id', 'Variation', 'clnt_tenure_yr', 'age_group', 'confirm',\n",
       "       'start', 'step_1', 'step_2', 'step_3', 'drop_start_step_1',\n",
       "       'drop_step_1_step_2', 'drop_step_2_step_3', 'drop_step_3_confirm',\n",
       "       'tenure_group', 'confirm_filled', 'time_confirm', 'time_start',\n",
       "       'time_step_1', 'time_step_2', 'time_step_3', 'error_start_step_1',\n",
       "       'error_step_1_step_2', 'error_step_2_step_3', 'error_step_3_confirm',\n",
       "       'age_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7453d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ df_merged ready with 317123 rows\n",
      "   client_id Variation  clnt_tenure_yr age_group  confirm  start  step_1  \\\n",
      "0        555      Test             3.0     25-34      5.0    5.0     5.0   \n",
      "1        555      Test             3.0     25-34      5.0    5.0     5.0   \n",
      "2        555      Test             3.0     25-34      5.0    5.0     5.0   \n",
      "3        555      Test             3.0     25-34      5.0    5.0     5.0   \n",
      "4        555      Test             3.0     25-34      5.0    5.0     5.0   \n",
      "\n",
      "   step_2  step_3  drop_start_step_1  ...  time_step_1  time_step_2  \\\n",
      "0     5.0     5.0                0.0  ...        158.0        158.0   \n",
      "1     5.0     5.0                0.0  ...        158.0        158.0   \n",
      "2     5.0     5.0                0.0  ...        158.0        158.0   \n",
      "3     5.0     5.0                0.0  ...        158.0        158.0   \n",
      "4     5.0     5.0                0.0  ...        158.0        158.0   \n",
      "\n",
      "   time_step_3 error_start_step_1  error_step_1_step_2  error_step_2_step_3  \\\n",
      "0        158.0                  0                    0                    0   \n",
      "1        158.0                  0                    0                    0   \n",
      "2        158.0                  0                    0                    0   \n",
      "3        158.0                  0                    0                    0   \n",
      "4        158.0                  0                    0                    0   \n",
      "\n",
      "   error_step_3_confirm  age_num  session_duration_sec  num_sessions  \n",
      "0                     0       30                 158.0             1  \n",
      "1                     0       30                 158.0             1  \n",
      "2                     0       30                 158.0             1  \n",
      "3                     0       30                 158.0             1  \n",
      "4                     0       30                 158.0             1  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge both datasets on client_id and Variation\n",
    "df_merged = df_pivot_2.merge(\n",
    "    df_abtest[['client_id','Variation','session_duration_sec','num_sessions']], \n",
    "    on=['client_id','Variation'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(\"✅ df_merged ready with\", df_merged.shape[0], \"rows\")\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e6065",
   "metadata": {},
   "source": [
    "**4.- Session Duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb06c499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Session Duration Hypothesis Test ===\n",
      "T-statistic: -20.0454, p-value: 0.0000\n",
      "✅ Significant difference in session duration between Control and Test.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# --- Session Duration Test ---\n",
    "print(\"\\n=== Session Duration Hypothesis Test ===\")\n",
    "\n",
    "control_dur = df_merged[df_merged['Variation'] == 'Control']['session_duration_sec'].dropna()\n",
    "test_dur = df_merged[df_merged['Variation'] == 'Test']['session_duration_sec'].dropna()\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(control_dur, test_dur, equal_var=False)  # Welch’s t-test\n",
    "print(f\"T-statistic: {t_stat:.4f}, p-value: {p_val:.4f}\")\n",
    "if p_val < 0.05:\n",
    "    print(\"✅ Significant difference in session duration between Control and Test.\")\n",
    "else:\n",
    "    print(\"❌ No significant difference in session duration between Control and Test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "725edcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Session Duration Test by Age Group ===\n",
      "Age Group 25-34: t=-5.3870, p=0.0000\n",
      "Age Group 55-64: t=-15.4652, p=0.0000\n",
      "Age Group 45-54: t=-2.6498, p=0.0081\n",
      "Age Group 35-44: t=-3.9571, p=0.0001\n",
      "Age Group <25: t=-10.8114, p=0.0000\n",
      "Age Group 65+: t=-12.4318, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "# === SESSION DURATION TEST BY AGE GROUP ===\n",
    "print(\"=== Session Duration Test by Age Group ===\")\n",
    "for age in df_merged['age_group'].unique():\n",
    "    control_dur = df_merged[(df_merged['Variation']=='Control') & (df_merged['age_group']==age)]['session_duration_sec'].dropna()\n",
    "    test_dur = df_merged[(df_merged['Variation']=='Test') & (df_merged['age_group']==age)]['session_duration_sec'].dropna()\n",
    "    t_stat, p_val = stats.ttest_ind(control_dur, test_dur, equal_var=False)\n",
    "    print(f\"Age Group {age}: t={t_stat:.4f}, p={p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "281a1b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Session Duration Test by Tenure Group ===\n",
      "Tenure Group less-tenured: t=-11.3996, p=0.0000\n",
      "Tenure Group more-tenured: t=-17.5140, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "# === SESSION DURATION TEST BY TENURE GROUP ===\n",
    "print(\"\\n=== Session Duration Test by Tenure Group ===\")\n",
    "for tenure in df_merged['tenure_group'].unique():\n",
    "    control_dur = df_merged[(df_merged['Variation']=='Control') & (df_merged['tenure_group']==tenure)]['session_duration_sec'].dropna()\n",
    "    test_dur = df_merged[(df_merged['Variation']=='Test') & (df_merged['tenure_group']==tenure)]['session_duration_sec'].dropna()\n",
    "    t_stat, p_val = stats.ttest_ind(control_dur, test_dur, equal_var=False)\n",
    "    print(f\"Tenure Group {tenure}: t={t_stat:.4f}, p={p_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99288e5c",
   "metadata": {},
   "source": [
    "- **Overall T-Test**: t = -20.0454, p < 0.001 → ✅ Significant difference; users spend more time in Test.\n",
    "- **By Age Group**: Significant increases in all age groups, especially <25, 55-64, and 65+.\n",
    "- **By Tenure Group**: Significant increases in both less-tenured and more-tenured groups.\n",
    "- **Conclusion**: Test design **increases session duration**, particularly for younger and older users, and for long-tenured clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f709cc9",
   "metadata": {},
   "source": [
    "**5.- Error Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8ee4836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Error Rate Hypothesis Test ===\n",
      "T-statistic: -48.4221, p-value: 0.0000\n",
      "✅ Significant difference in error rate between Control and Test.\n"
     ]
    }
   ],
   "source": [
    "# --- Error Rate Test ---\n",
    "print(\"\\n=== Error Rate Hypothesis Test ===\")\n",
    "\n",
    "# Define error-related columns from df_pivot_2\n",
    "error_cols = [\n",
    "    'error_start_step_1',\n",
    "    'error_step_1_step_2',\n",
    "    'error_step_2_step_3',\n",
    "    'error_step_3_confirm'\n",
    "]\n",
    "\n",
    "# Calculate total errors per client\n",
    "df_merged['total_errors'] = df_merged[error_cols].sum(axis=1)\n",
    "\n",
    "control_err = df_merged[df_merged['Variation'] == 'Control']['total_errors']\n",
    "test_err = df_merged[df_merged['Variation'] == 'Test']['total_errors']\n",
    "\n",
    "t_stat_err, p_val_err = stats.ttest_ind(control_err, test_err, equal_var=False)\n",
    "print(f\"T-statistic: {t_stat_err:.4f}, p-value: {p_val_err:.4f}\")\n",
    "if p_val_err < 0.05:\n",
    "    print(\"✅ Significant difference in error rate between Control and Test.\")\n",
    "else:\n",
    "    print(\"❌ No significant difference in error rate between Control and Test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ed3f937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Error Rate Test by Age Group ===\n",
      "Age Group 25-34: t=-12.1706, p=0.0000\n",
      "Age Group 55-64: t=-27.6511, p=0.0000\n",
      "Age Group 45-54: t=-20.9647, p=0.0000\n",
      "Age Group 35-44: t=-19.4594, p=0.0000\n",
      "Age Group <25: t=-6.4526, p=0.0000\n",
      "Age Group 65+: t=-24.8998, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "# === ERROR RATE TEST BY AGE GROUP ===\n",
    "print(\"\\n=== Error Rate Test by Age Group ===\")\n",
    "for age in df_merged['age_group'].unique():\n",
    "    control_err = df_merged[(df_merged['Variation']=='Control') & (df_merged['age_group']==age)]['total_errors']\n",
    "    test_err = df_merged[(df_merged['Variation']=='Test') & (df_merged['age_group']==age)]['total_errors']\n",
    "    t_stat, p_val = stats.ttest_ind(control_err, test_err, equal_var=False)\n",
    "    print(f\"Age Group {age}: t={t_stat:.4f}, p={p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64ca268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Error Rate Test by Tenure Group ===\n",
      "Tenure Group less-tenured: t=-36.2220, p=0.0000\n",
      "Tenure Group more-tenured: t=-32.2341, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "# === ERROR RATE TEST BY TENURE GROUP ===\n",
    "print(\"\\n=== Error Rate Test by Tenure Group ===\")\n",
    "for tenure in df_merged['tenure_group'].unique():\n",
    "    control_err = df_merged[(df_merged['Variation']=='Control') & (df_merged['tenure_group']==tenure)]['total_errors']\n",
    "    test_err = df_merged[(df_merged['Variation']=='Test') & (df_merged['tenure_group']==tenure)]['total_errors']\n",
    "    t_stat, p_val = stats.ttest_ind(control_err, test_err, equal_var=False)\n",
    "    print(f\"Tenure Group {tenure}: t={t_stat:.4f}, p={p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42dc65",
   "metadata": {},
   "source": [
    "- **Overall T-Test**: t = -48.4221, p < 0.001 → ✅ Significant difference; error rate is higher in Test.\n",
    "- **By Age Group**: All age groups show significantly higher errors in Test, especially 55-64 and 65+.\n",
    "- **By Tenure Group**: Both less-tenured and more-tenured users have significantly higher errors in Test.\n",
    "- **Conclusion**: Test design **increases errors**, particularly at the final confirm step and among older or more experienced users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca63e74b",
   "metadata": {},
   "source": [
    "**✅ Final Summary**\n",
    "\n",
    "- **Completion Rate**: Slight improvement in Test, **not statistically significant**, below 5% cost-effectiveness threshold.\n",
    "\n",
    "- **Session Duration**: Test increases time spent per step, especially for <25, 55+, 65+, and long-tenured users.\n",
    "\n",
    "- **Error Rates**: Test shows higher errors across all steps, **particularly the confirm step**.\n",
    "\n",
    "- **Overall**: Test design slightly improves completion but reduces efficiency and increases errors in key user segments → careful consideration needed before adoption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4335ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary by Variation ===\n",
      "           Completion Rate  Avg Duration (sec)  Avg Error Rate\n",
      "Variation                                                     \n",
      "Control              0.656             604.918           0.007\n",
      "Test                 0.693             773.191           0.015\n",
      "                     Completion Rate  Avg Duration (sec)  Avg Error Rate\n",
      "Variation Age Group                                                     \n",
      "Test      25-34                0.716             515.109           0.011\n",
      "          55-64                0.696             994.762           0.019\n",
      "          45-54                0.686             832.251           0.017\n",
      "          35-44                0.704             582.669           0.013\n",
      "          <25                  0.709             582.254           0.011\n",
      "          65+                  0.639            1092.483           0.019\n",
      "Control   25-34                0.670             449.343           0.006\n",
      "          55-64                0.661             714.427           0.008\n",
      "          45-54                0.670             659.441           0.007\n",
      "          35-44                0.675             505.423           0.006\n",
      "          <25                  0.651             426.774           0.005\n",
      "          65+                  0.587             801.172           0.008\n",
      "                        Completion Rate  Avg Duration (sec)  Avg Error Rate\n",
      "Variation Tenure Group                                                     \n",
      "Test      less-tenured            0.697             781.845           0.016\n",
      "          more-tenured            0.689             764.703           0.015\n",
      "Control   less-tenured            0.653             613.998           0.007\n",
      "          more-tenured            0.659             595.761           0.007\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 1. Prepare summary for Variation\n",
    "# ------------------------------\n",
    "variation_summary = pd.DataFrame({\n",
    "    \"Completion Rate\": completion_rate,   # from your previous calculations\n",
    "    \"Avg Duration (sec)\": df_pivot_2[['time_start','time_step_1','time_step_2','time_step_3','time_confirm']].mean(axis=1).groupby(df_pivot_2['Variation']).mean(),\n",
    "    \"Avg Error Rate\": df_pivot_2[['error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']].mean(axis=1).groupby(df_pivot_2['Variation']).mean()\n",
    "})\n",
    "\n",
    "# Round for readability\n",
    "variation_summary = variation_summary.round(3)\n",
    "print(\"=== Summary by Variation ===\")\n",
    "print(variation_summary)\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Prepare summary by Age Group (fixed)\n",
    "# ------------------------------\n",
    "age_summary = []\n",
    "\n",
    "for var in df_pivot_2['Variation'].unique():\n",
    "    for age in df_pivot_2['age_group'].unique():\n",
    "        subset = df_pivot_2[(df_pivot_2['Variation']==var) & (df_pivot_2['age_group']==age)]\n",
    "        completion = (subset['confirm_filled']>0).mean()\n",
    "        avg_duration = subset[['time_start','time_step_1','time_step_2','time_step_3','time_confirm']].mean(axis=1).mean()\n",
    "        avg_error = subset[['error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']].mean(axis=1).mean()\n",
    "        # Append as a dict\n",
    "        age_summary.append({\n",
    "            'Variation': var,\n",
    "            'Age Group': age,\n",
    "            'Completion Rate': round(completion, 3),\n",
    "            'Avg Duration (sec)': round(avg_duration, 3),\n",
    "            'Avg Error Rate': round(avg_error, 3)\n",
    "        })\n",
    "\n",
    "age_summary = pd.DataFrame(age_summary)\n",
    "age_summary.set_index(['Variation','Age Group'], inplace=True)\n",
    "print(age_summary)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Prepare summary by Tenure Group\n",
    "# ------------------------------\n",
    "tenure_summary = []\n",
    "\n",
    "for var in df_pivot_2['Variation'].unique():\n",
    "    for tenure in df_pivot_2['tenure_group'].unique():\n",
    "        subset = df_pivot_2[(df_pivot_2['Variation']==var) & (df_pivot_2['tenure_group']==tenure)]\n",
    "        completion = (subset['confirm_filled']>0).mean()\n",
    "        avg_duration = subset[['time_start','time_step_1','time_step_2','time_step_3','time_confirm']].mean(axis=1).mean()\n",
    "        avg_error = subset[['error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']].mean(axis=1).mean()\n",
    "        tenure_summary.append({\n",
    "            'Variation': var,\n",
    "            'Tenure Group': tenure,\n",
    "            'Completion Rate': round(completion, 3),\n",
    "            'Avg Duration (sec)': round(avg_duration, 3),\n",
    "            'Avg Error Rate': round(avg_error, 3)\n",
    "        })\n",
    "\n",
    "tenure_summary = pd.DataFrame(tenure_summary)\n",
    "tenure_summary.set_index(['Variation','Tenure Group'], inplace=True)\n",
    "print(tenure_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16f4701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV for Variation saved!\n",
      "✅ CSV for Age Group saved!\n",
      "✅ CSV for Tenure Group saved!\n",
      "✅ Client-level long format CSV saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ------------------------------\n",
    "# 1️⃣ Summary by Variation\n",
    "# ------------------------------\n",
    "variation_summary = pd.DataFrame({\n",
    "    \"Variation\": df_pivot_2['Variation'].unique()\n",
    "})\n",
    "\n",
    "# Completion Rate\n",
    "completion_rate = df_pivot_2.groupby('Variation')['confirm_filled'].apply(lambda x: (x>0).mean()).reset_index(drop=True)\n",
    "variation_summary['Completion Rate'] = (completion_rate*100).round(2)  # as percentage\n",
    "\n",
    "# Avg Duration (sec)\n",
    "avg_duration = df_pivot_2[['Variation','time_start','time_step_1','time_step_2','time_step_3','time_confirm']].copy()\n",
    "avg_duration['Avg Duration (sec)'] = avg_duration[['time_start','time_step_1','time_step_2','time_step_3','time_confirm']].mean(axis=1)\n",
    "avg_duration_summary = avg_duration.groupby('Variation')['Avg Duration (sec)'].mean().reset_index(drop=True)\n",
    "variation_summary['Avg Duration (sec)'] = avg_duration_summary.round(2)\n",
    "\n",
    "# Avg Error Rate\n",
    "avg_error = df_pivot_2[['Variation','error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']].copy()\n",
    "avg_error['Avg Error Rate'] = avg_error[['error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']].mean(axis=1)\n",
    "avg_error_summary = avg_error.groupby('Variation')['Avg Error Rate'].mean().reset_index(drop=True)\n",
    "variation_summary['Avg Error Rate'] = avg_error_summary.round(3)\n",
    "\n",
    "# Export CSV\n",
    "variation_summary.to_csv(\"tableau_summary_by_variation.csv\", index=False)\n",
    "print(\"✅ CSV for Variation saved!\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2️⃣ Summary by Age Group\n",
    "# ------------------------------\n",
    "age_summary = []\n",
    "\n",
    "for var in df_pivot_2['Variation'].unique():\n",
    "    for age in df_pivot_2['age_group'].unique():\n",
    "        subset = df_pivot_2[(df_pivot_2['Variation']==var) & (df_pivot_2['age_group']==age)]\n",
    "        completion = (subset['confirm_filled']>0).mean()\n",
    "        avg_duration = subset[['time_start','time_step_1','time_step_2','time_step_3','time_confirm']].mean(axis=1).mean()\n",
    "        avg_error = subset[['error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']].mean(axis=1).mean()\n",
    "        age_summary.append({\n",
    "            'Variation': var,\n",
    "            'Age Group': age,\n",
    "            'Completion Rate': round(completion*100,2),\n",
    "            'Avg Duration (sec)': round(avg_duration,2),\n",
    "            'Avg Error Rate': round(avg_error,3)\n",
    "        })\n",
    "\n",
    "age_summary = pd.DataFrame(age_summary)\n",
    "age_summary.to_csv(\"tableau_summary_by_age.csv\", index=False)\n",
    "print(\"✅ CSV for Age Group saved!\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3️⃣ Summary by Tenure Group\n",
    "# ------------------------------\n",
    "tenure_summary = []\n",
    "\n",
    "for var in df_pivot_2['Variation'].unique():\n",
    "    for tenure in df_pivot_2['tenure_group'].unique():\n",
    "        subset = df_pivot_2[(df_pivot_2['Variation']==var) & (df_pivot_2['tenure_group']==tenure)]\n",
    "        completion = (subset['confirm_filled']>0).mean()\n",
    "        avg_duration = subset[['time_start','time_step_1','time_step_2','time_step_3','time_confirm']].mean(axis=1).mean()\n",
    "        avg_error = subset[['error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']].mean(axis=1).mean()\n",
    "        tenure_summary.append({\n",
    "            'Variation': var,\n",
    "            'Tenure Group': tenure,\n",
    "            'Completion Rate': round(completion*100,2),\n",
    "            'Avg Duration (sec)': round(avg_duration,2),\n",
    "            'Avg Error Rate': round(avg_error,3)\n",
    "        })\n",
    "\n",
    "tenure_summary = pd.DataFrame(tenure_summary)\n",
    "tenure_summary.to_csv(\"tableau_summary_by_tenure.csv\", index=False)\n",
    "print(\"✅ CSV for Tenure Group saved!\")\n",
    "\n",
    "# ------------------------------\n",
    "# 4️⃣ Optional: Long Format Client-Level Data (for advanced Tableau analysis)\n",
    "# ------------------------------\n",
    "df_pivot_2.to_csv(\"tableau_client_long_format.csv\", index=False)\n",
    "print(\"✅ Client-level long format CSV saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fca6bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client_id Variation Age Group  Tenure Group process_step  reached_step\n",
      "0        555      Test     25-34  less-tenured        start             1\n",
      "1        555      Test     25-34  less-tenured       step_1             1\n",
      "2        555      Test     25-34  less-tenured       step_2             1\n",
      "3        555      Test     25-34  less-tenured       step_3             1\n",
      "4        555      Test     25-34  less-tenured      confirm             1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Columns that indicate reaching a step (any non-NaN or non-zero)\n",
    "steps = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "\n",
    "# Create a long format dataframe for steps reached\n",
    "records = []\n",
    "for _, row in df_pivot_2.iterrows():\n",
    "    for step in steps:\n",
    "        reached = 1 if pd.notna(row[step]) and row[step] > 0 else 0\n",
    "        records.append({\n",
    "            'client_id': row['client_id'],\n",
    "            'Variation': row['Variation'],\n",
    "            'Age Group': row['age_group'],\n",
    "            'Tenure Group': row['tenure_group'],\n",
    "            'process_step': step,\n",
    "            'reached_step': reached\n",
    "        })\n",
    "\n",
    "df_steps_long = pd.DataFrame(records)\n",
    "\n",
    "# Save to CSV to import into Tableau\n",
    "df_steps_long.to_csv(\"tableau_steps_long.csv\", index=False)\n",
    "print(df_steps_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d3eb7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV exportados: variation_summary.csv, age_summary.csv, tenure_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear columna auxiliar con el error medio por fila\n",
    "df_pivot_2[\"row_error_mean\"] = df_pivot_2[\n",
    "    [\"error_start_step_1\",\"error_step_1_step_2\",\"error_step_2_step_3\",\"error_step_3_confirm\"]\n",
    "].mean(axis=1)\n",
    "\n",
    "# Crear columna auxiliar con la duración media por fila\n",
    "df_pivot_2[\"row_duration_mean\"] = df_pivot_2[\n",
    "    [\"time_start\",\"time_step_1\",\"time_step_2\",\"time_step_3\",\"time_confirm\"]\n",
    "].mean(axis=1)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Summary by Variation\n",
    "# ------------------------------\n",
    "variation_summary = (\n",
    "    df_pivot_2.groupby(\"Variation\")\n",
    "    .agg(\n",
    "        Completion_Rate=(\"confirm_filled\", lambda x: (x > 0).mean()),\n",
    "        Avg_Duration_sec=(\"row_duration_mean\", \"mean\"),\n",
    "        Avg_Error_Rate=(\"row_error_mean\", \"mean\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "variation_summary = variation_summary.round(3)\n",
    "variation_summary.to_csv(\"variation_summary.csv\", index=False)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Summary by Age Group\n",
    "# ------------------------------\n",
    "age_summary = (\n",
    "    df_pivot_2.groupby([\"Variation\",\"age_group\"])\n",
    "    .agg(\n",
    "        Completion_Rate=(\"confirm_filled\", lambda x: (x > 0).mean()),\n",
    "        Avg_Duration_sec=(\"row_duration_mean\", \"mean\"),\n",
    "        Avg_Error_Rate=(\"row_error_mean\", \"mean\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "age_summary = age_summary.round(3)\n",
    "age_summary.to_csv(\"age_summary.csv\", index=False)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Summary by Tenure Group\n",
    "# ------------------------------\n",
    "tenure_summary = (\n",
    "    df_pivot_2.groupby([\"Variation\",\"tenure_group\"])\n",
    "    .agg(\n",
    "        Completion_Rate=(\"confirm_filled\", lambda x: (x > 0).mean()),\n",
    "        Avg_Duration_sec=(\"row_duration_mean\", \"mean\"),\n",
    "        Avg_Error_Rate=(\"row_error_mean\", \"mean\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "tenure_summary = tenure_summary.round(3)\n",
    "tenure_summary.to_csv(\"tenure_summary.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"✅ CSV exportados: variation_summary.csv, age_summary.csv, tenure_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "878e0dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long-format table ready for Tableau!\n",
      "   client_id Variation age_group  tenure_group process_step  \\\n",
      "0        555      Test     25-34  less-tenured        start   \n",
      "1        555      Test     25-34  less-tenured        start   \n",
      "2        555      Test     25-34  less-tenured        start   \n",
      "3        555      Test     25-34  less-tenured        start   \n",
      "4        555      Test     25-34  less-tenured        start   \n",
      "\n",
      "   session_duration_sec  error  completed  \n",
      "0                 158.0    NaN          0  \n",
      "1                 158.0    NaN          0  \n",
      "2                 158.0    NaN          0  \n",
      "3                 158.0    NaN          0  \n",
      "4                 158.0    NaN          0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Select relevant columns ---\n",
    "# session durations per step, error rates per step, plus client info\n",
    "cols_duration = ['client_id', 'Variation', 'age_group', 'tenure_group',\n",
    "                 'time_start', 'time_step_1', 'time_step_2', 'time_step_3', 'time_confirm']\n",
    "\n",
    "cols_error = ['error_start_step_1', 'error_step_1_step_2', 'error_step_2_step_3', 'error_step_3_confirm']\n",
    "\n",
    "df_tableau = df_merged[cols_duration + cols_error].copy()\n",
    "\n",
    "# --- Step 2: Melt session duration columns into long format ---\n",
    "df_duration_long = df_tableau.melt(\n",
    "    id_vars=['client_id', 'Variation', 'age_group', 'tenure_group'],\n",
    "    value_vars=['time_start', 'time_step_1', 'time_step_2', 'time_step_3', 'time_confirm'],\n",
    "    var_name='process_step',\n",
    "    value_name='session_duration_sec'\n",
    ")\n",
    "\n",
    "# Optional: clean step names\n",
    "df_duration_long['process_step'] = df_duration_long['process_step'].str.replace('time_', '')\n",
    "\n",
    "# --- Step 3: Melt error columns into long format ---\n",
    "df_error_long = df_tableau.melt(\n",
    "    id_vars=['client_id', 'Variation', 'age_group', 'tenure_group'],\n",
    "    value_vars=['error_start_step_1', 'error_step_1_step_2', 'error_step_2_step_3', 'error_step_3_confirm'],\n",
    "    var_name='process_step',\n",
    "    value_name='error'\n",
    ")\n",
    "\n",
    "# Optional: clean step names to match session duration\n",
    "df_error_long['process_step'] = df_error_long['process_step'].str.replace('error_', '').str.replace('_', '')\n",
    "\n",
    "# --- Step 4: Merge session duration and error long tables ---\n",
    "df_long = pd.merge(\n",
    "    df_duration_long,\n",
    "    df_error_long,\n",
    "    on=['client_id', 'Variation', 'age_group', 'tenure_group', 'process_step'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Step 5: Add completion flag ---\n",
    "# If 'process_step' is 'confirm' and session_duration_sec > 0, then completed\n",
    "df_long['completed'] = df_long.apply(\n",
    "    lambda row: 1 if row['process_step']=='confirm' and row['session_duration_sec']>0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Step 6: Export to CSV for Tableau ---\n",
    "df_long.to_csv('tableau_client_long_format.csv', index=False)\n",
    "\n",
    "print(\"Long-format table ready for Tableau!\")\n",
    "print(df_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06dc112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pre-aggregated summary tables are ready for Tableau!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Define the main df ---\n",
    "df = df_merged.copy()  # Make sure df_merged has age_group and tenure_group\n",
    "\n",
    "# --- Step 2: Completion rate summary ---\n",
    "# Fill missing confirm with 0\n",
    "df['confirm_filled'] = df['time_confirm'].fillna(0)\n",
    "df['completed'] = df['confirm_filled'].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "# Completion rate by Variation\n",
    "completion_var = df.groupby('Variation')['completed'].mean().reset_index()\n",
    "completion_var.rename(columns={'completed':'completion_rate'}, inplace=True)\n",
    "\n",
    "# Completion rate by Age Group\n",
    "completion_age = df.groupby(['Variation','age_group'])['completed'].mean().reset_index()\n",
    "completion_age.rename(columns={'completed':'completion_rate'}, inplace=True)\n",
    "\n",
    "# Completion rate by Tenure Group\n",
    "completion_tenure = df.groupby(['Variation','tenure_group'])['completed'].mean().reset_index()\n",
    "completion_tenure.rename(columns={'completed':'completion_rate'}, inplace=True)\n",
    "\n",
    "# --- Step 3: Session duration summary ---\n",
    "session_cols = ['time_start','time_step_1','time_step_2','time_step_3','time_confirm']\n",
    "\n",
    "# Melt session durations\n",
    "df_duration_long = df.melt(\n",
    "    id_vars=['client_id','Variation','age_group','tenure_group'],\n",
    "    value_vars=session_cols,\n",
    "    var_name='process_step',\n",
    "    value_name='duration_sec'\n",
    ")\n",
    "df_duration_long['process_step'] = df_duration_long['process_step'].str.replace('time_','')\n",
    "\n",
    "# Aggregate avg duration\n",
    "avg_duration_var = df_duration_long.groupby(['Variation','process_step'])['duration_sec'].mean().reset_index()\n",
    "avg_duration_age = df_duration_long.groupby(['Variation','age_group','process_step'])['duration_sec'].mean().reset_index()\n",
    "avg_duration_tenure = df_duration_long.groupby(['Variation','tenure_group','process_step'])['duration_sec'].mean().reset_index()\n",
    "\n",
    "# --- Step 4: Error rate summary ---\n",
    "error_cols = ['error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']\n",
    "\n",
    "df_error_long = df.melt(\n",
    "    id_vars=['client_id','Variation','age_group','tenure_group'],\n",
    "    value_vars=error_cols,\n",
    "    var_name='process_step',\n",
    "    value_name='error_rate'\n",
    ")\n",
    "df_error_long['process_step'] = df_error_long['process_step'].str.replace('error_','').str.replace('_','')\n",
    "\n",
    "# Aggregate avg error rate\n",
    "avg_error_var = df_error_long.groupby(['Variation','process_step'])['error_rate'].mean().reset_index()\n",
    "avg_error_age = df_error_long.groupby(['Variation','age_group','process_step'])['error_rate'].mean().reset_index()\n",
    "avg_error_tenure = df_error_long.groupby(['Variation','tenure_group','process_step'])['error_rate'].mean().reset_index()\n",
    "\n",
    "# --- Step 5: Export CSVs ---\n",
    "completion_var.to_csv('tableau_completion_by_variation.csv', index=False)\n",
    "completion_age.to_csv('tableau_completion_by_age.csv', index=False)\n",
    "completion_tenure.to_csv('tableau_completion_by_tenure.csv', index=False)\n",
    "\n",
    "avg_duration_var.to_csv('tableau_duration_by_variation.csv', index=False)\n",
    "avg_duration_age.to_csv('tableau_duration_by_age.csv', index=False)\n",
    "avg_duration_tenure.to_csv('tableau_duration_by_tenure.csv', index=False)\n",
    "\n",
    "avg_error_var.to_csv('tableau_error_by_variation.csv', index=False)\n",
    "avg_error_age.to_csv('tableau_error_by_age.csv', index=False)\n",
    "avg_error_tenure.to_csv('tableau_error_by_tenure.csv', index=False)\n",
    "\n",
    "print(\"All pre-aggregated summary tables are ready for Tableau!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f778e375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df_pivot_2: 50487\n",
      "Unique clients: 50487\n",
      "Variations: {'Test': 26961, 'Control': 23526}\n",
      "Expected rows (clients * steps): 252435 -> long rows: 252435\n",
      "Saved tableau_steps_long_corrected.csv\n",
      "Saved tableau_step_counts_by_variation.csv\n",
      "Saved tableau_step_counts_by_age.csv\n",
      "Saved tableau_step_counts_by_tenure.csv\n",
      "Saved tableau_step_retention_by_variation.csv\n",
      "\n",
      "Sanity checks (Variation-level % reached):\n",
      "Variation process_step  n_reached  n_clients  pct_reached\n",
      "  Control        start      23391      23526     0.994262\n",
      "  Control       step_1      20146      23526     0.856329\n",
      "  Control       step_2      18644      23526     0.792485\n",
      "  Control       step_3      17416      23526     0.740287\n",
      "  Control      confirm      15428      23526     0.655785\n",
      "     Test        start      26672      26961     0.989281\n",
      "     Test       step_1      24260      26961     0.899818\n",
      "     Test       step_2      22252      26961     0.825340\n",
      "     Test       step_3      20876      26961     0.774304\n",
      "     Test      confirm      18682      26961     0.692927\n",
      "\n",
      "Sanity checks (by age, sample):\n",
      "Variation age_group process_step  n_reached  n_clients  pct_reached\n",
      "  Control     25-34        start       4784       4817     0.993149\n",
      "  Control     25-34       step_1       4151       4817     0.861740\n",
      "  Control     25-34       step_2       3928       4817     0.815445\n",
      "  Control     25-34       step_3       3573       4817     0.741748\n",
      "  Control     25-34      confirm       3227       4817     0.669919\n",
      "  Control     35-44        start       3950       3966     0.995966\n",
      "  Control     35-44       step_1       3391       3966     0.855018\n",
      "  Control     35-44       step_2       3188       3966     0.803833\n",
      "  Control     35-44       step_3       2938       3966     0.740797\n",
      "  Control     35-44      confirm       2678       3966     0.675240\n",
      "Saved duration long and avg duration CSVs.\n",
      "Saved error long and avg error CSVs.\n",
      "\n",
      "All CSVs for step-level analysis have been created. Import these into Tableau:\n",
      "- tableau_steps_long_corrected.csv\n",
      "- tableau_step_counts_by_variation.csv\n",
      "- tableau_step_counts_by_age.csv\n",
      "- tableau_step_counts_by_tenure.csv\n",
      "- tableau_step_retention_by_variation.csv\n",
      "- (optional) tableau_duration_long_by_client.csv, tableau_avg_duration_by_variation_step.csv\n",
      "- (optional) tableau_error_long_by_client.csv, tableau_avg_error_by_variation_step.csv\n"
     ]
    }
   ],
   "source": [
    "# Reproducible export pipeline -> create long step table + aggregated CSVs for Tableau\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- SETTINGS: steps order (important) ---\n",
    "steps = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "\n",
    "# --- 0. Quick checks (optional) ---\n",
    "print(\"Rows in df_pivot_2:\", len(df_pivot_2))\n",
    "print(\"Unique clients:\", df_pivot_2['client_id'].nunique())\n",
    "print(\"Variations:\", df_pivot_2['Variation'].value_counts().to_dict())\n",
    "\n",
    "# --- 1. Create client-level long table with reached_step (1 if user reached that step) ---\n",
    "long_frames = []\n",
    "for step in steps:\n",
    "    tmp = df_pivot_2[['client_id','Variation','age_group','tenure_group', step]].copy()\n",
    "    tmp = tmp.rename(columns={step: 'step_value'})\n",
    "    tmp['process_step'] = step\n",
    "    # Define reached: not null AND >0 (adjust if your step_value indicates presence differently)\n",
    "    # If some step_value can be 0 and still considered \"reached\", change condition accordingly.\n",
    "    tmp['reached_step'] = np.where(tmp['step_value'].notna() & (tmp['step_value'] > 0), 1, 0)\n",
    "    # Keep any duration per step if you have time_* columns named similarly; if not, leave NaN\n",
    "    # If you have time columns named time_start etc, we can map them later.\n",
    "    long_frames.append(tmp[['client_id','Variation','age_group','tenure_group','process_step','reached_step']])\n",
    "\n",
    "df_steps_long = pd.concat(long_frames, ignore_index=True)\n",
    "\n",
    "# Sanity: each client should have one row per step\n",
    "n_clients = df_pivot_2['client_id'].nunique()\n",
    "expected_rows = n_clients * len(steps)\n",
    "print(\"Expected rows (clients * steps):\", expected_rows, \"-> long rows:\", len(df_steps_long))\n",
    "\n",
    "# Save client-level long table\n",
    "df_steps_long.to_csv(\"tableau_steps_long_corrected.csv\", index=False)\n",
    "print(\"Saved tableau_steps_long_corrected.csv\")\n",
    "\n",
    "# --- 2. Aggregations: counts and percent reached by Variation & Step ---\n",
    "# Count of reached per variation-step\n",
    "counts_var_step = (\n",
    "    df_steps_long.groupby(['Variation','process_step'])['reached_step']\n",
    "    .agg(n_reached='sum')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# denominator per variation: number of unique clients in that variation\n",
    "denom_var = df_pivot_2.groupby('Variation')['client_id'].nunique().reset_index().rename(columns={'client_id':'n_clients'})\n",
    "counts_var_step = counts_var_step.merge(denom_var, on='Variation', how='left')\n",
    "counts_var_step['pct_reached'] = counts_var_step['n_reached'] / counts_var_step['n_clients']\n",
    "\n",
    "# Order process_step as categorical for later use (and to ensure CSV shows human order)\n",
    "counts_var_step['process_step'] = pd.Categorical(counts_var_step['process_step'], categories=steps, ordered=True)\n",
    "counts_var_step = counts_var_step.sort_values(['Variation','process_step'])\n",
    "\n",
    "counts_var_step.to_csv(\"tableau_step_counts_by_variation.csv\", index=False)\n",
    "print(\"Saved tableau_step_counts_by_variation.csv\")\n",
    "\n",
    "# --- 3. Aggregations by Variation x Age Group x Step ---\n",
    "counts_var_age_step = (\n",
    "    df_steps_long.groupby(['Variation','age_group','process_step'])['reached_step']\n",
    "    .agg(n_reached='sum')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# denom per variation-age for percentages\n",
    "denom_var_age = df_pivot_2.groupby(['Variation','age_group'])['client_id'].nunique().reset_index().rename(columns={'client_id':'n_clients'})\n",
    "counts_var_age_step = counts_var_age_step.merge(denom_var_age, on=['Variation','age_group'], how='left')\n",
    "counts_var_age_step['pct_reached'] = counts_var_age_step['n_reached'] / counts_var_age_step['n_clients']\n",
    "\n",
    "counts_var_age_step['process_step'] = pd.Categorical(counts_var_age_step['process_step'], categories=steps, ordered=True)\n",
    "counts_var_age_step = counts_var_age_step.sort_values(['Variation','age_group','process_step'])\n",
    "counts_var_age_step.to_csv(\"tableau_step_counts_by_age.csv\", index=False)\n",
    "print(\"Saved tableau_step_counts_by_age.csv\")\n",
    "\n",
    "# --- 4. Aggregations by Variation x Tenure Group x Step ---\n",
    "counts_var_tenure_step = (\n",
    "    df_steps_long.groupby(['Variation','tenure_group','process_step'])['reached_step']\n",
    "    .agg(n_reached='sum')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "denom_var_tenure = df_pivot_2.groupby(['Variation','tenure_group'])['client_id'].nunique().reset_index().rename(columns={'client_id':'n_clients'})\n",
    "counts_var_tenure_step = counts_var_tenure_step.merge(denom_var_tenure, on=['Variation','tenure_group'], how='left')\n",
    "counts_var_tenure_step['pct_reached'] = counts_var_tenure_step['n_reached'] / counts_var_tenure_step['n_clients']\n",
    "\n",
    "counts_var_tenure_step['process_step'] = pd.Categorical(counts_var_tenure_step['process_step'], categories=steps, ordered=True)\n",
    "counts_var_tenure_step = counts_var_tenure_step.sort_values(['Variation','tenure_group','process_step'])\n",
    "counts_var_tenure_step.to_csv(\"tableau_step_counts_by_tenure.csv\", index=False)\n",
    "print(\"Saved tableau_step_counts_by_tenure.csv\")\n",
    "\n",
    "# --- 5. Progression/Retention between steps (Variation-level) ---\n",
    "# compute pct_reached pivot-like structure quickly\n",
    "pivot_var = counts_var_step.pivot(index='Variation', columns='process_step', values='n_reached').reset_index()\n",
    "# safe fill zero for missing\n",
    "pivot_var = pivot_var.fillna(0)\n",
    "\n",
    "# compute retention from step i to step i+1 = n_reached(step_{i+1}) / n_reached(step_i)\n",
    "# careful with zeros: where n_reached(step_i)==0 set NaN\n",
    "retentions = []\n",
    "for var in pivot_var['Variation']:\n",
    "    row = pivot_var[pivot_var['Variation']==var].iloc[0]\n",
    "    ret = {'Variation': var}\n",
    "    for i in range(len(steps)-1):\n",
    "        s_prev = steps[i]\n",
    "        s_next = steps[i+1]\n",
    "        prev_n = row.get(s_prev, 0)\n",
    "        next_n = row.get(s_next, 0)\n",
    "        if prev_n > 0:\n",
    "            ret_rate = next_n / prev_n\n",
    "        else:\n",
    "            ret_rate = np.nan\n",
    "        ret[f'retention_{s_prev}_to_{s_next}'] = ret_rate\n",
    "    retentions.append(ret)\n",
    "retention_df = pd.DataFrame(retentions)\n",
    "retention_df.to_csv(\"tableau_step_retention_by_variation.csv\", index=False)\n",
    "print(\"Saved tableau_step_retention_by_variation.csv\")\n",
    "\n",
    "# --- 6. Sanity checks prints (small) ---\n",
    "print(\"\\nSanity checks (Variation-level % reached):\")\n",
    "print(counts_var_step[['Variation','process_step','n_reached','n_clients','pct_reached']].to_string(index=False))\n",
    "\n",
    "print(\"\\nSanity checks (by age, sample):\")\n",
    "# show a small sample for one variation and one age\n",
    "print(counts_var_age_step[counts_var_age_step['Variation']=='Control'].head(10).to_string(index=False))\n",
    "\n",
    "# --- 7. (Optional) include session duration per step in a long format for Tableau plotting time-by-step\n",
    "# If df_pivot_2 has time_x columns (time_start etc) we melt them\n",
    "time_cols = ['time_start','time_step_1','time_step_2','time_step_3','time_confirm']\n",
    "if set(time_cols).issubset(df_pivot_2.columns):\n",
    "    df_time_long = df_pivot_2[['client_id','Variation','age_group','tenure_group'] + time_cols].melt(\n",
    "        id_vars=['client_id','Variation','age_group','tenure_group'],\n",
    "        value_vars=time_cols,\n",
    "        var_name='process_step',\n",
    "        value_name='duration_sec'\n",
    "    )\n",
    "    df_time_long['process_step'] = df_time_long['process_step'].str.replace('time_','')\n",
    "    df_time_long.to_csv(\"tableau_duration_long_by_client.csv\", index=False)\n",
    "    # also aggregate averages\n",
    "    avg_time_by_var_step = df_time_long.groupby(['Variation','process_step'])['duration_sec'].mean().reset_index()\n",
    "    avg_time_by_var_step.to_csv(\"tableau_avg_duration_by_variation_step.csv\", index=False)\n",
    "    print(\"Saved duration long and avg duration CSVs.\")\n",
    "else:\n",
    "    print(\"time_cols not present in df_pivot_2; skipping duration exports.\")\n",
    "\n",
    "# --- 8. (Optional) include error per step long format if needed ---\n",
    "error_cols = ['error_start_step_1','error_step_1_step_2','error_step_2_step_3','error_step_3_confirm']\n",
    "if set(error_cols).issubset(df_pivot_2.columns):\n",
    "    df_error_long = df_pivot_2[['client_id','Variation','age_group','tenure_group'] + error_cols].melt(\n",
    "        id_vars=['client_id','Variation','age_group','tenure_group'],\n",
    "        value_vars=error_cols,\n",
    "        var_name='process_step',\n",
    "        value_name='error'\n",
    "    )\n",
    "    # normalize names to match steps (optional)\n",
    "    df_error_long['process_step'] = df_error_long['process_step'].str.replace('error_','').str.replace('_','')\n",
    "    df_error_long.to_csv(\"tableau_error_long_by_client.csv\", index=False)\n",
    "    # aggregate\n",
    "    avg_error_by_var_step = df_error_long.groupby(['Variation','process_step'])['error'].mean().reset_index()\n",
    "    avg_error_by_var_step.to_csv(\"tableau_avg_error_by_variation_step.csv\", index=False)\n",
    "    print(\"Saved error long and avg error CSVs.\")\n",
    "else:\n",
    "    print(\"error_cols not present in df_pivot_2; skipping error exports.\")\n",
    "\n",
    "print(\"\\nAll CSVs for step-level analysis have been created. Import these into Tableau:\")\n",
    "print(\"- tableau_steps_long_corrected.csv\")\n",
    "print(\"- tableau_step_counts_by_variation.csv\")\n",
    "print(\"- tableau_step_counts_by_age.csv\")\n",
    "print(\"- tableau_step_counts_by_tenure.csv\")\n",
    "print(\"- tableau_step_retention_by_variation.csv\")\n",
    "print(\"- (optional) tableau_duration_long_by_client.csv, tableau_avg_duration_by_variation_step.csv\")\n",
    "print(\"- (optional) tableau_error_long_by_client.csv, tableau_avg_error_by_variation_step.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
